<!--
 * @Description:
 * @author: kelly
 * @Date: 2024-05-14 14:42:33
 * @LastEditTime: 2024-05-22 10:52:38
-->

## Node.js 面试试题总结

### 对于 Node.js 的理解，有什么优缺点？可以怎么使用呢？

#### 概念：

Node.js 是一个开源与跨平台的 Javascript 运行环境，在浏览器外运行 V8 Javascript 引擎（Google Chrome 的内核），利用事件驱动，非阻塞和异步输入输出模型等技术提高性能。

简单来说，就是一个服务器端的、非阻塞式 I/O 的、事件驱动的 JS 运行环境。

- 非阻塞异步

`Node.js`采用了非阻塞型 I/O 机制，在做 I/O 操作的时候不会造成任何的阻塞，当完成之后，以时间的形式通知执行操作

例如在执行了访问数据库的代码之后，将立即转而执行其后面的代码，把数据库返回结果的处理代码放在回调函数中，从而提高了程序的执行效率。

- 事件驱动

事件驱动就是当进来一个新的请求时，请求将会被压入一个事件队列中，然后通过一个循环来检测队列中的事件状态变化，如果检测到有状态变化的事件，那么就执行该事件对应的处理代码，一般都是回调函数。

比如读取一个文件，文件读取完毕后，就会触发对应的状态，然后通过对应的回调函数来进行处理

下面用一张图来直观地展示事件驱动的原理：

![f88d92e6e22d14a78585ab50a2fbf3d.png](https://s2.loli.net/2024/05/14/mauUFDP8yZ7IgsY.png)

#### 优缺点：

##### 优点：

- 处理高并发场景性能更好一些

- 适合 I/O 密集型应用，简单讲就是当应用在运行极限时，CPU 占用率仍然比较低，大部分时间是在做 I/O 硬盘内存读写操作

##### 缺点：

Node.js 的缺点主要是由它本是是单线程所致的，主要体现在：

- 不适合 CPU 密集型应用

- 只支持单核 CPU，不能充分利用 CPU

- 可靠性低，一旦代码某个环节奔溃，整个系统都会奔溃

#### 应用场景：

结合他的优缺点可以从这三个方面入手考虑应用的使用场景：

1. 善于 I/O，不善于计算。因为 Node.js 是一个单线程，如果计算（同步）太多，则会阻塞这个线程

-

2. 大量并发 的 I/O，应用程序内部并不需要进行非常复杂的处理

3. 与 WebSocket 配合，开发长连接的实时交互应用程序

从上面的三个方面，具体的使用表现有：

场景 1. 用户表单收集系统、后台管理系统、考试系统、联网系统、高并发量的 web 应用程序

场景 2. 基于 web、canvas 等多人联网游戏

场景 3. 基于 web 的多人实时聊天客户端、聊天室、图文直播

场景 4. 单页面浏览器应用程序

场景 5. 操作数据库、为前端和移动端提供基于`json`的`API`

### Node 中的`fs`模块你有什么理解？

#### 概念：

fs(filesystem)，该模块提供本地文件的读写能力，基本上是 POSIX 文件操作命令的简单包装，换种方式说，所有的文件操作都是通过`fs`核心模块实现的。

```js
const fs = require('fs');
```

这个模块对所有文件系统操作提供异步（不具备 sync 后缀）和同步（具有 sync 后缀）两种操作方式供开发者选择。

#### 常见的方法：

- 文件读取

- 文件写入

- 文件追加写入

- 文件拷贝

- 创建目录

##### 文件读取

1. fs.readFileSync

`同步读取`

第一个参数：读取文件的路径或者文件描述符

第二个参数：options，默认是为 null，其中 EnCoding（编码。默认值为 null）和 flag（标识位，默认为 r），也可直接传入 encoding

结果为返回文件的内容。

```javascript
const fs = require('fs');

let buf = fs.readFileSync(path.join(__dirname, '1.txt'));
let data = fs.readFileSync(path.join(__dirname, '1.txt`, "utf-8"));

console.log(buf);
console.log(data);
```

2. fs.readFile

`异步读取`

与同步读取的前两个参数一致

最后一个参数为回调函数，函数内有两个参数 err 和 data，该方法没有返回值，回调函数在读取文件成功后执行

```js
const fs = require('fs');

fs.readFile('1.txt', 'utf8', (err, data) => {
  if (!err) {
    console.log(data); // hello
  }
});
```

##### 文件写入

1. writeFileSync

`同步写入`

三个参数：

第一个参数：文件路径或文件描述符

第二个参数：写入的数据，类型为 String 或 buffer

第三个参数：options，默认为 null，其中 EnCoding（编码。默认值为 utf-8）、 flag（标识位，默认为 w）和 mode（权限位，默认 0o666），也可直接传入 encoding

```js
const fs = require('fs');

fs.writeFileSync('2.txt', 'hello world');
let data = fs.readFileSync('2.txt', 'utf8');

console.log(data);
```

2. writeFile

`异步写入`

与同步读取的前三个参数一致

最后一个参数为回调函数，函数内有一个参数 err（错误），回调函数在文件写入数据成功后执行

```js
const fs = require('fs');

FS.writeFile('2.txt', 'hello world', (err) => {
  if (!err) {
    fs.readFile('2.txt', 'utf-8', (err, data) => {
      console.log(data);
    });
  }
});
```

##### 文件追加写入

1. appendFileSync

第一个参数：写入文件的路径或者文件描述符

第二个参数：写入的数据，类型为 String 或者 Buffer

第三个参数：options，默认为 null，其中 EnCoding（编码，默认为 utf-8）、flag（标识位，默认为 a）和 mode（权限位，默认为 0o666），也可以直接传入 eccoding

```js
const fs = require('fs');

fs.appendFileSync('3.txt', 'word');

let data = fs.readFileSync('3.txt', 'utf8');
```

2. appendFile

前三个参数与 appendFileSync 一样

最后一个参数为回调函数，函数内一个参数 err，回调函数在文件追加写入数据成功后执行

```js
const fs = require('fs');

fs.appendFile("3.txt", "word", err => {
  if(!err){
    fs.readFile('3.txt', 'utf8', (err, data))=>{
      console.log(data);
    }
  }
})
```

##### 文件拷贝

1. copyFileSync

`同步拷贝`

```js
const fs = require('fs');

fs.copyFileSync('3.txt', '4.txt');
let data = fs.readFileSync('4.txt', 'utf8');

console.log(data); // Hello world
```

2. copyFile

```js
const fs = require('fs');

fs.copyFile('3.txt', '4.txt', () => {
  fs.readFile('4.txt', 'utf8', (err, data) => {
    console.log(data); // Hello world
  });
});
```

##### 创建目录

1. mkdirSync

`同步创建`

参数为一个目录的路径，没有返回值，在创建目录的过程中，必须保证传入的路径前面的文件都存在，否则会抛出异常

```js
// 假设已经有了a文件夹和a文件夹下的b 文件夹
fs.mkdirSync('a/b/c');
```

2. mkdir

`异步创建`

第二个参数为回调函数

```js
fs.mkdir('a/b/c', (err) => {
  if (!err) console.log(' ');
});
```

### Buffer 你是怎么理解的？

#### 概念

准确来说，Buffer 是一种计算机中数据流结构。计算机中是以二进制的方式，进行数据存取的。

而 JS 在一开始，没有文件读写能力的，就要借助 Buffer 来实现一些缓冲区的内容。

Buffer 一般用于固定长度的缓冲区序列

其存储的方式如下图所示：

![16b308336f88b497dfaf9b25d38e72f.png](https://s2.loli.net/2024/05/14/TBb3PGZKeLHhnfu.png)

#### 使用方法

Buffer 在全局作用域中，无须 require 导入

创建 Buffer 的常见形式：

- Buffer.from()

```js
const b1 = Buffer.from('10');
const b2 = Buffer.from('10', 'utf8');
const b3 = Buffer.from([10]);
const b4 = Buffer.from(b3);
console.log(b1, b2, b3, b4); // <Buffer 31 30> <Buffer 31 30> <Buffer 0a> <Buffer 0a>
```

- Buffer.alloc()

```js
const bAlloc1 = Buffer.alloc(10); // 创建一个大小为10个字节的缓冲区
const bAlloc2 = Buffer.alloc(10, 1); // 创建一个长度为10 的Buffer,其中全部填充了值为1的字节

console.log(bAlloc1); // <Buffer 00 00 00 00 00 00 00 00 00 00>
console.log(bAlloc2); // <Buffer 01 01 01 01 01 01 01 01 01 01>
```

#### 应用场景

Buffer 的应用场景常与流（Stream）的概念联系在一起，主要有以下几个应用场景：

- I/O 操作

通过流的形式，将一个文件的内容读取到另一个文件中

```js
const fs = require('fs');

const inputStream = fs.createReadStream('input.txt'); // 创建可读流
const outputStream = fs.createWriteStream('output.txt'); // 创建可写流

inputStream.pipe(outputStream); // 管道读写
```

- 加密解密

在一些加密算法中会遇到使用 Buffer，例如 crypto.createCipheriv 的第二个参数 key 为 string 或 buffer 类型

- zlib.js

zlib.js 为 Node.js 的核心库之一，其利用了缓冲区（Buffer）的功能来操作二进制数据流，提供了压缩或解压的功能

### Stream 你是怎么理解的呢？有使用过吗？

#### 概念

流（Stream），是一个数据传输手段，是端到端信息交换的一种方式，而且是有顺序的，是逐块读取数据、处理内容，用于顺序读取输入或者写入输出

Node.js 中很多对象都实现了流，总之他是会冒数据（以 Buffer 为单位）

他的独特之处：不像传统的程序那样一次性全部读入内存，而是逐块读取数据、处理其内容，而不是将其全部保存在内存中。

流可以分为三个部分：source、dest、pipe

在 source 和 dest 之间有一个连接的管道 pipe，他的基本语法是 `source.pipe(dest)`，`source` 和`dest`就是通过`pipe`连接，让数据从`source`流向`dest`

#### 种类

在 NodeJs 中，几乎所有的地方都使用了流的概念，分为 4 类：

- 可写流：可写入数据的流（单向的）。例如`fs.createWriteStream()`可以使用流将数据写入文件

- 可读流：可读取数据的流（单向的）。例如`fs.createReadStream()`可以使用流从文件中读取数据

- 双工流：即可读又可写的流。例如 `net.Socket`

- 转换流：可以在数据写入和读取时修改或者转换数据的流。例如，在文件压缩操作中，可以向文件写入压缩数据，并从文件中读取解压数据

下面重点我们来说说双工流：

我们之前了解过的`websocket`通信，其实就是一个全双工通信，发送方和接收方都是各自独立的方法，发送与接收都没有任何关系

如下图所示：

![16b308336f88b497dfaf9b25d38e72f.png](https://s2.loli.net/2024/05/14/TBb3PGZKeLHhnfu.png)

基本代码：

```js
const { Duplex } = require('stream');

const myDuplex = new Duplex({
  read(size) {
    // ...
  },
  write(chunk, encoding, callback) {
    // ...
  },
});
```

双工流示意图：

![d9fe20dfebefc2254d84cdf66d77033.png](https://s2.loli.net/2024/05/16/h4Mu2K75xgJGVHI.png)

除了上述压缩包的例子，还比如 babel，把 es6 转换为 es5，我们在左边写入 es6 ，从右边读取 es5

基本代码如下：

```js
const { Transform } = require('stream');

const myTransform = new Transform({
  transform(chunk, encoding, callback) {
    // ...
  },
});
```

#### 应用场景

stream 的应用场景主要是处理 I/O 操作，而 http 请求和文件操作都是属于 IO 操作

如果一次 I/O 操作过大，硬件的开销就过大，而将此次大的 I/O 操作进行分段操作，让数据像水管一样流动，知道流动完成

常见场景：

- get 请求返回文件给客户端

使用 stream 流返回文件，res 也是一个 stream 对象，通过 pipe 管道将文件数据返回

```js
const server = http.createServer(function (req, res) {
  const method = req.method;
  if (method == 'GET') {
    const fileName = path.resolve(__dirname, 'data.txt');
    let stream = fs.createReadStream(fileName);
    stream.pipe(res);
  }
});

server.listen(8080);
```

- 文件操作

创建一个可读数据流 readStream，一个可写数据流 writeStream，通过 pipe 管道把数据流转

```js
const fs = require('fs');
const path = require('path');
// 两个文件
const fileName1 = path.resolve(__dirname, 'data.txt');
const fileName2 = path.resolve(__dirname, 'data-bak.txt');
// 读取文件的 stream 对象
const readStream = fs.createReadStream(fileName1);
// 写入文件的 stream 对象
const writeStream = fs.createWriteStream(fileName2);
// 通过 pipe 执行拷贝，数据流转
readStream.pipe(writeStream);
// 数据读取完成监听，即拷贝完成
readStream.on('end', function () {
  console.log('拷贝完成');
});
```

- 一些打包工具的底层操作

目前比较流行的打包构建工具都是用 Node.js 写的，因为打包和构建肯定是文件频繁的操作过程，离不开 Stream，如 `gulp`

### process 你是怎么理解的呢？有哪些常用的方法？

#### 概念理解

process 对象是一个全局变量，提供了有关当前 Node.js 进程的信息并对其进行控制，作为一个全局变量

进程是计算机系统进行资源分配和调度的基本单位，是操作系统结构的基础，是线程的容器

当我们启动一个 js 文件，实际就是开启了一个服务进程，每个进程都拥有自己的独立空间地址、数据栈，像另一个进程无法访问当前进程的变量、数据结构，只有数据通信后，进程之间才可以数据共享。由于 JS 是一个单线程，所以通过 node 启动一个文件后，只有一条主线程。

#### 属性与方法

常见的属性有：

- process.env:环境变量，例如通过`process.NODE_ENV`获取不同环境项目配置信息

- process.nextTick:这个在谈及 EventLoop 时经常会被提到

- process.pid: 获取当前进程的 id

- process.ppid: 当前进程的父进程

- process.cwd(): 获取当前进程的工作目录

- process.platform：获取当前进程运行的操作系统平台

- process.uptime(): 当前进程已运行的时间，例如 pm2 守护进程的 uptime 值

- 进程事件：process.on('uncaughtException', cb) 捕获异常信息、process.on('exit', cb)进程退出监听

- 三个标准流：

  - process.stdout 标准输出
  - process.stdin 标准输入
  - process.stderr 标准错误输出

- process.title 指定进程名称，有的时候需要给进程指定一个名称

常见的方法：

- process.cwd()

返回当前 Node 进程执行的目录

一个 Node 模块 A 通过 NPM 发布，项目 B 使用了模块 A。在 A 中需要操作 B 项目下的文件时，就可以使用 process.cwd() 来获取 B 的路径

- process.argv

在终端通过 Node 执行命令的时候，通过 process.argv 可以获取传入放入命令行的参数，返回的是一个数组：

1. 0：Node 路径（可忽略）

2. 1：被执行的ＪＳ文件路径（可忽略）

3. 2~n：真实传入命令的参数

所以，我们可以从 process.argv[2]开始获取就好了

```js
const args = process.argv.slice(2);
```

- process.env

返回一个对象，存储当前环境相关的所有信息。

一般我们会在 process.env 上挂载一些变量标识当前的环境。比如最常见的用 `process.env.NODE_EN` 来区别 development 和 production

在 vue-cli 的源码中也会经常看到 process.env.VUE_CLI_DEBUG 标识当前是不是 DEBUG 模式

- process.nextTick()

NodeJS 是基于事件轮询，这个过程中，同一个时间内只会处理一个事件

在这种处理模式下， process.nextTick() 就是定义出一个动作，并且让这个动作在下一个事件轮询的时间点上执行

例如下面例子将一个 foo 函数在下一个时间点调用

```js
function foo() {
  console.error('foo');
}
process.nextTick(foo);
console.error('bar');
// bar  foo
```

虽然也可以使用 setTimeout 实现一样的效果：

```js
setTimeout(foo, 0);
console.log('bar');
```

但是两者的区别在于：

1. process.nextTick()会在这一次 event loop 的 call stack 清空后（下一次 event loop 开始前）再调用 callback

2. setTimeout()是并不知道什么时候 call stack 清空的，所有调用 callback 函数是不确定的

### 对于 Node 中的 EventEmitter 是怎么理解的呢？如何实现一个呢？

#### 概念

我们了解到，Node 采用了`事件驱动机制`，而`EventEmitter`就是 Node 实现事件驱动的基础。

在 EventEmitter 的基础上，Node 几乎所有的模块都继承了这个类，这些模块拥有了自己的事件。可以绑定/ 触发监听器，实现了异步操作。

Node.js 里面的许多对象都会分发事件，比如 fs.EventEmitter 的实例，这些对象会在文件被打开的时候触发一个事件，这些产生的对象都是 events.EventEmitter 的实例，这些对象有一个 eventEmitter.on()函数，用于将一个或多个函数绑定到命名事件上。

#### 使用方法

Node 的 events 模块只提供了一个 EventEmitter 类，这个类实现了 Node 异步事件驱动架构的基本模式--观察者模式。

在这种模式下，被观察者（主体）维护者一组其他对象派来的（注册） 的观察者，有新的对象对主体感兴趣就注册观察者，不感兴趣就取消订阅，主体有更新的话就依次通知观察者们。

基本代码如下：

```js
const EventEmitter = require('events');

class MyEmitter extends EventEmitter {}
const myEmitter = new MyEmitter();

function callback() {
  console.log('触发了 event 事件！');
}

myEmitter.on('event', callback);
myEmitter.emit('event');
myEmitter.removeListener('event', callback);
```

通过实例对象 on 的方法注册一个名为 event 的事件，通过 emit 的方法触发该事件，而 removeListener 用于取消事件的监听

关于其常见方法如下：

- emitter.addListener/on(eventName, listener): 添加了类型为 eventName 的监听事件到事件数组尾部

- emitter.prependListener(eventName, listener): 添加了类型为 eventName 的监听事件到事件数组头部

- emitter.emit(eventName, [,...args]): 触发类型为 eventName 的监听事件

- emitter.removeListener/off(eventName, listener): 移除类型为 eventName 的监听事件

- emitter.removeAllListeners([eventName]): 移除全部类型为 eventName 的监听事件

#### 实现过程

通过上面的方法了解，EventEmitter 是一个构造函数，内部存在一个包含所有事件的对象

```js
class EventEmitter {
  constructor() {
    this.events = {};
  }
}
```

其中 events 存放的监听事件的函数的结构如下：

```js
{
 "event1": [f1,f2,f3]
 "event2": [f4,f5]
 ...
}
```

然后开始一步步实现实例方法，首先是 emit，第一个参数为事件的类型，第二个参数开始为触发事件函数的参数，实现如下：

```js

emit(type, ...args){
  this.events[type].forEach((item)=> {
    Reflect.apply(item, args);
  })
}
```

当实现了 emit 方法之后，然后实现 on/addListener/prependListener 这三个实例方法，都是添加事件监听触发函数，实现也大同小异

```js
on(type, handler) {
 if (!this.events[type]) {
  this.events[type] = [];
 }
 this.events[type].push(handler);
}
addListener(type,handler){
 this.on(type,handler)
}
prependListener(type, handler) {
 if (!this.events[type]) {
  this.events[type] = [];
 }
 this.events[type].unshift(handler);
}
```

紧接着实现事件监听的方法 removeListener/on

```js
removeListener(type, handler) {
 if (!this.events[type]) {
  return;
 }
 this.events[type] = this.events[type].filter(item => item !== handler)
;
}
off(type,handler){
 this.removeListener(type,handler)
}
```

最后再来实现 once 方法，再传入事件监听处理函数的时候进行封装，利用闭包的特性维护当前状态，通过 fired 属性值来判断事件函数与是否执行过

```js
once(type, handler) {
  this.on(type, this._onceWrap(type, handler, this));
}

_onceWrap(type, handler, target) {
    const state = { fired: false, handler, type , target};
    const wrapFn = this._onceWrapper.bind(state);
    state.wrapFn = wrapFn;
    return wrapFn;
}

_onceWrapper(...args) {
  if (!this.fired) {
      this.fired = true;
      Reflect.apply(this.handler, this.target, args);
      this.target.off(this.type, this.wrapFn);
  }
}
```

完成代码如下：

```js
class EventEmitter {
  constructor() {
    this.events = {};
  }

  on(type, handler) {
    if (!this.events[type]) {
      this.events[type] = [];
    }
    this.events[type].push(handler);
  }

  addListener(type, handler) {
    this.on(type, handler);
  }

  prependListener(type, handler) {
    if (!this.events[type]) {
      this.events[type] = [];
    }
    this.events[type].unshift(handler);
  }

  removeListener(type, handler) {
    if (!this.events[type]) {
      return;
    }
    this.events[type] = this.events[type].filter((item) => item !== handler);
  }

  off(type, handler) {
    this.removeListener(type, handler);
  }

  emit(type, ...args) {
    this.events[type].forEach((item) => {
      Reflect.apply(item, this, args);
    });
  }

  once(type, handler) {
    this.on(type, this._onceWrap(type, handler, this));
  }

  _onceWrap(type, handler, target) {
    const state = { fired: false, handler, type, target };
    const wrapFn = this._onceWrapper.bind(state);
    state.wrapFn = wrapFn;
    return wrapFn;
  }
  _onceWrapper(...args) {
    if (!this.fired) {
      this.fired = true;
      Reflect.apply(this.handler, this.target, args);
      this.target.off(this.type, this.wrapFn);
    }
  }
}
```

测试代码：

```js
const ee = new EventEmitter();

// 注册所有事件
ee.once('wakeUp', (name) => {
  console.log(`${name} 1`);
});
ee.on('eat', (name) => {
  console.log(`${name} 2`);
});
ee.on('eat', (name) => {
  console.log(`${name} 3`);
});
const meetingFn = (name) => {
  console.log(`${name} 4`);
};
ee.on('work', meetingFn);
ee.on('work', (name) => {
  console.log(`${name} 5`);
});
ee.emit('wakeUp', 'xx');
ee.emit('wakeUp', 'xx'); // 第二次没有触发
ee.emit('eat', 'xx');
ee.emit('work', 'xx');
ee.off('work', meetingFn); // 移除事件
ee.emit('work', 'xx'); // 再次工作
```

### Node 文件查找的优先级以及 require 方法的文件查找策略？

#### 模块规范

NodeJS 对 CommonJS 进行了支持和实现，让我们在开发 node 的过程中可以方便进行模块化开发：

- 在 Node 中每一个 JS 文件都是一个单独的模块

- 模块中包括 CommonJS 规范的核心变量：exports、module.exports、require

- 通过上述变量进行模块化开发

而模块化的核心是导入与导出，在 Node 中通过 exports 与 module.exports 负责对模块中的内容进行导出，通过 require 函数导入其他模块中的内容

#### 查找策略

require 方法接收一下集中参数的传递：

- 原生模块：http、fs、path 等

- 相对路径的文件模块：./mod 或../mod

- 绝对路径的文件模块： /pathtomodule/mod

- 目录作为模块：./dirname

- 非原生模块的文件模块： mod

require 参数较为简单，但是内部的加载却是非常复杂的，其加载优先级也是各自不同。

![7ae8271772b824a4172f3e55f8c2c95.png](https://s2.loli.net/2024/05/17/tybNKOz1JFxhREe.png)

1. 原生模块

原生模块通过 require 方法在解析文件名之后，优先检查模块是否在原生模块列表中，如果在则从原生模块中加载

2. 绝对路径、相对路径

如果 require 绝对路径的文件，则会直接查找对应的路径，速度最快

相对路径的模块则相对当前调用 require 的文件去查找

如果按确切的文件名没有找到模块，则 NodeJs 会尝试带上.js、.json 或.node 拓展名再加载

3. 目录作为模块

默认情况下时根据目录中 package.json 文件的 main 来指定目录模块，如：

```js
{
  "name": "some-library",
  "main": "main.js"
}
```

如果这是在./some-library node_modules 目录中，则 require(./some-library)会试图加载 ./some-library/main.js

如果目录里没有 package.json 文件，或者 main 入口不存在或者无法解析，则会试图加载目录下的 index.js 或 index.node 文件

4. 非原生模块

在每个文件中都存在 module.paths，表示模块的搜索路径，require 就是根据其来寻找文件在 window 下输出如下：

```js
['C:\\nodejs\\node_modules', 'C:\\node_modules'];
```

可以看出 module path 的生成规则为：从当前文件目录开始查找 node_modules 目录；然后依次进入父目录，查找父目录下的 node_modules 目录，依次迭代，直到根目录下的 node_modules 目录。

如果找不到的时候，则会从系统 NODE_PATH 环境变量查找

**举个例子：**

如果在`/home/ry/projects/foo.js`文件中调用 `require('bar.js')`， 则 Node.js 会按以下顺序查找：

    - /home/ry/projects/node_modules/bar.js
    - /home/ry/node_modules/bar.js
    - /home/node_modules/bar.js
    - /node_modules/bar.js

这使得程序本地优化他们的依赖，避免他们产生冲突。

**总结：**

通过上面模块的文件查找策略之后，总结下文查找的优先级：

- 缓存的模块优先级最高

- 如果是内置模块，则直接返回，优先级仅次于缓存的模块

- 如果是绝对路径/开头，则从根目录查找

- 如果是相对路径/开头，则从当前 require 文件相对位置查找

- 如果文件没有携带后缀，先从 js/json/node 按顺序查找

- 如果是目录，则根据 package.json 的 main 属性值决定目录下入口文件，默认情况为 index.js

- 如果文件为第三方模块，则会引入 node_mogules 文件，如果不在当前仓库文件中，则自动从上级递归查找，知道根目录

### 你对 Node 中间件是怎么理解的呢？如何封装呢？

#### 概念

中间件是介于应用系统和系统软件之间的一类软件，它使用系统软件所提供的基础服务（功能），衔接网络上应用系统的各个部分或者不同的应用，能够达到资源共享，功能共享的目的。

在 NodeJS 中，中间件主要是指封装 http 请求细节处理的方法

例如在 express、koa 等 web 架构中，中间件的本质为一个回调函数，参数包含请求对象、响应对象和执行下一个中间件的函数

![d475bb1af98e59547a5e02aeca209a0.png](https://s2.loli.net/2024/05/20/edTIr136bg4iXqW.png)

在这些中间件函数中，我们可以执行业务逻辑代码、修改请求和响应对象，返回响应数据等操作

#### 在应用中实现封装功能模块

`koa`是基于 NodeJS 当前比较流行的 web 框架，本身支持的功能并不多，功能都可以通过中间件的拓展实现。通过添加不同的中间件，实现不同的需求，从而构建一个 Koa 应用。

Koa 中间件采用的是洋葱圈模型，每次执行下一个中间件传入两个参数：

- ctx:封装了 request 和 response 的变量

- next: 进入下一个要执行的中间件的函数

下面针对 koa 进行中间件的封装：

Koa 的中间件就是函数，可以是 async 函数，或者是普通函数

```js
// async函数
app.use(async (ctx, next) => {
  const start = Date.now();
  await next();
  const ms = Date.now() - start;
  console.log(`${ctx.method} ${ctx.url} - ${ms}ms`);
});

// 普通函数
app.use((ctx, next) => {
  const ms = Date.now();
  return next().then(() => {
    const ms = Date.now - start;
    console.log(`${ctx.method} ${ctx.url} - ${ms}ms`);
  });
});
```

下面则通过中间件封装 http 请求过程中几个常见的功能：

1. token 校验

```js
module.exports = (options) => async(ctx, next){
  try{
    // 获取token
    const token = ctx.header.authorization;
    if(token){
      try(
        // verify 函数验证token,并获取用户相关信息
        await verify(token);
      )catch(err){
        console.log(err);
      }
    }
    // 进入下一个中间件
    await next();
  } catch(err){
    console.log(err);
  }
}
```

2. 日志模块

```js
const fs = require('fs');
module.exports = (options) => async (ctx, next) => {
  const startTime = Date.now();
  const requestTime = new Date();
  await next();
  const ms = Date.now() - startTime;
  let logout = `${ctx.request.ip} -- ${requestTime} -- ${ctx.method} -- ${ctx.url} -- ${ms}ms`;

  // 输出日志
  fs.appendFileSync('./log.txt', logout + '\n');
};
```

`Koa`还存在很多第三方的中间件，如 koa-bodyparser、koa-static 等

3. koa-bodyparser

koa-bodyparser 中间件是将我们的 post 请求和表单提交的查询字符串转化为对象，并挂在 ctx.request.body 上，方便我们在其他中间件或者接口处取值

```js
// 文件： my-koa-bodyparser.js
const querystring = require('querystring');

module.exports = function bodyParser() {
  return async (ctx, next) => {
    await new Promise((resolve, reject) => {
      // 存储数据的数组
      let dataArr = [];

      // 接收数据
      ctx.req.on('data', (data) => dataArr.push(data));

      // 整合数据并使用 Promise 成功
      ctx.req.on('end', () => {
        // 获取请求数据的类型 json格式
        let contentType = ctx.get('Content-Type');

        // 或者数据 Buffer 格式
        let data = Buffer.concat(dataArr).toString();

        if (contentType === 'application/x-www-form-urlencoded') {
          // 如果是表单提交，则将查询字符串转换为对象赋值给 ctx.request.body;
          ctx.request.body = querystring.parse(data);
        } else if (contentType === 'applaction/json') {
          // 如果是json，则将字符串格式的对象转为对象赋值给 ctx.request.body;
          ctx.request.body = JSON.parse(data);
        }
        // 执行成功的回调
        resolve();
      });
    });

    // 继续向下执行
    await next();
  };
};
```

4. koa-static

koa-static 中间件的作用是在服务器接到请求后，帮我们处理静态文件

```js
const fs = require('fs');
const path = require('path');
const mime = require('mime');
const { promisify } = require('util');

// 将stat 和 access转换为Promise
const stat = promisify(fs.stat);
const access = promisify(fs.access);

module.exports = function (dir) {
  return async (ctx, next) => {
    // 将访问的路由处理成绝对路径，这里要使用join,因为有可能是 /
    let realPath = path.join(dir, ctx.path);

    try {
      // 获取stat对象
      let statObj = await stat(realPath);

      // 如果是文件，则设置文件类型并直接响应内容，否则当做文件夹寻找index.html
      if (statObj.isFile()) {
        ctx.set('Content-Type', `${mime.getType()};charset=utf8`);
        ctx.body = fs.createReadStream(realPath);
      } else {
        let filename = path.join(realPath, 'index.html');

        // 如果不存在该文件则执行catch中的next交给其他中间件处理
        await access(filename);

        // 存在设置文件类型并响应内容
        ctx.set('Content-Type', 'text/html;charset=utf8');
        ctx.body = fs.createReadStream(filename);
      }
    } catch (e) {
      await next();
    }
  };
};
```

#### 总结

在实现中间件的时候，单个中间件应用足够简单，职责单一，中间件代码编写应该是高效的，必要时通过缓存避免重复获取数据。

koa 本身比较简洁，但是通过中间件的机制能够实现各种所需要的功能，使得 web 应用具备良好的可拓展性和组合型。

通过将公共逻辑的处理编写在中间件中，可以不用在每个接口回调中做相同的代码编写，减少了冗杂代码，过程就如装饰者模式。

### 说说 NodeJS 中的事件循环机制？

#### 概念

在浏览器事件循环中，我们了解到 JavaScript 在浏览器中的事件循环机制，其是根据 HTML5 定义的规范来实现的。

而在 NodeJS 中，事件循环是基于 libuv 实现，libuv 是一个多平台的专注于异步 IO 的库

#### 流程

NodeJS 事件循环分为 6 个阶段：

![e6824cefe0ec24189065c0d48ff2e7e.png](https://s2.loli.net/2024/05/20/PiuUtATICsdGWfL.png)

- timers: 执行 timer（setTimeout/setInterval）的回调

- 定时器检测阶段（timers）：执行 timer 的回调

- I/O 事件回调阶段（I/O callbacks）:执行延迟到下一个循环迭代的 I/O 回调，即上一轮循环中未被执行的一些 I/O 回调

- 闲置阶段（idle、prepare）：仅系统内部使用

- 轮询阶段（poll）：检索新的 I/O 事件，执行与 I/O 相关的回调（几乎所有情况下，除了关闭的回调函数，那些由计时器和 setImmediate()调度的之外），其余情况 node 将在适当的时候在此阻塞

- 检查阶段（check）：setImmediate()回调函数在这里执行

- 关闭事件回调阶段（close callback）：一些关闭的回调函数，直到队列耗尽或者回调的最大数量已执行，那么将进入下一个处理阶段

除了上述六个阶段，还存在 process.nextTick，其不属于事件循环的任何一个阶段，它属于该阶段与下一个阶段之间的过渡，即本阶段执行结束，进入下一个阶段前所有执行的回调，类似插队

流程图如下：

。。。。。。。。

在 Node 中同样存在宏任务与微任务，与浏览器中的事件循环类似

微任务对应有：

- next tick queue:process.nextTick

- other queue:Promise 的 then 回调、queueMicrotask

宏任务对应有：

- timer queue: setTimeout/setInterval

- poll queue: I/O 事件

- check queue:setImmediate

- close queue: close 事件

其执行顺序为：

- next tick queueMicrotask

- other Microtask queue

- timer queue

- poll queue

- check queue

- close queue

#### 相关题目

1. 题目一

```js
async function async1() {
  console.log('async1 start');
  await async2();
  console.log('async1 end'); // 微任务1
}
async function async2() {
  console.log('async2');
}
console.log('script start');
setTimeout(function () {
  console.log('setTimeout0'); // task1
}, 0);
setTimeout(function () {
  console.log('setTimeout2'); // task2
}, 300);
setImmediate(() => console.log('setImmediate')); // task3
process.nextTick(() => console.log('nextTick1'));
async1();
process.nextTick(() => console.log('nextTick2'));
new Promise(function (resolve) {
  console.log('promise1');
  resolve();
  console.log('promise2');
}).then(function () {
  console.log('promise3'); // 微任务2
});
console.log('script end');
```

分析过程：

（1）先找到同步任务，输出`script start`

（2）遇到第一个 setTimeout，将回调函数放在 timer 队列中

（3）遇到第二个 setTimeout，300ms 后将里面的回调函数放在 timer 队列中

（4）遇到 setImmediate，将里面的回调函数放在 check 队列中

（5）遇到第一个 nextTick，**将其里面的回调函数放在本轮同步任务执行完毕后执行**

（6）执行 async1 函数，输出`async1 start`

（7）执行 async2 函数，输出`async2`，async2 后面的代码可以被认为是微任务 1，等待下一轮的事件循环

（8）遇到第二个 nextTick，将其里面的回调函数放到本轮同步任务执行完毕后执行

（9）遇到 promise ，执行里面的立即执行函数，输出`promise1`、`promise2`

（10）then 里面的回调函数进入微任务队列 2

（11）遇到同步任务，输出 `script end`，此时同步任务结束了

（12）执行下一轮回调函数，先依次输出`nextTick1`、`nextTick2`，因为 nextTick 是放在本轮同步任务执行结束后执行的

（13）然后执行微任务队列，依次输出`async1 end`、`promise3`

（14）执行 timer 队列，依次输出`setTimeout0`

（14）接着执行 check 队列，输出`setImmediate`

（15）300ms 后，timer 继续执行任务，输出`setTimeout2`

输出结果：

> script start
> async1 start
> async2
> promise1
> promise2
> script end // 同步任务结束
> nextTick1
> nextTick2
> async1 end
> promise3
> setTimeout0
> setImmediate
> setTimeout2

2. 题目二

```js
setTimeout(() => {
  console.log('setTimeout');
}, 0);
setImmediate(() => {
  console.log('setImmediate');
});
```

分析过程：

（1）外层同步代码一次性全部执行完，遇到异步 API 就塞到对应的阶段

（2）遇到 setTimeout，虽然设置的是 0 毫秒触发，但是实际上会被强制改成 1ms，时间到了就塞入 timers 阶段

（3）遇到 setImmediate 塞入 check 阶段

（4）同步代码执行完毕，进入 Event Loop

（5）先进入 timers 阶段，检查当前时间过去了 1 毫秒了吗？满足 setTimeout 条件，执行回调，没有就跳过

（6）跳过空的阶段，进入 check，执行 setImmediate 回调

这里关键在于这 1 毫秒，如果同步代码太长，进入 event Loop 时，1 毫秒已经过了，就 setTimeout 先执行，否则就先执行 setImmediate

输出结果：

> // 情况 1:
> setTimeout
> setImmediate
> // 情况 2：
> setImmediate
> setTimeout

### 如果让你来设计一个分页功能，你会怎么设计以及实现？

#### 问题背景

在我们日常开发中，如果数据量很大，全部放在一个页面的话就很不友好，这时我们可以采用分页的方式，常见的是每页显示 10 条数据。

要实现分页功能，实际上就是从结果中获取 1-10 条数据为第一页，以此类推，因此我们需要从结果中获取第 M-N 条记录在第 a 页中展示。

#### 实现思路

前端实现分页功能，需要后端返回必要的数据，如总的页数，总的数据数，当前页，当前的数据等

```js
{
  "totalCount": 1830,
  "totalPages": 91,
  "currentPage": 1,
  "data": [{
    ...
  }]
}
```

后端采用 MySQL 作为数据的持久性存储

前端向后端发送目标的页面 `page` 以及每页显示数据的 `pageSize` ，默认情况下每次取 10 条数据，则每一条数据的起始位置 start 为：

```js
const start = (page - 1) * pageSize;
```

当确定了 limit 和 start 的值后，就能确定 SQL 语句：

```js
const sql = `SELECT * FROM record limit ${pageSize} OFFSET ${start};`;
```

上面的 SQL 语句表达的意思为：截取从 start 到 start + pageSize 之间（左闭右开）的数据

关于查询数据总数的 SQL 语句为（其中 record 为表明）：

```js
SELECT COUNT(*) FROM record
```

因此后端的处理逻辑为：

- 获取用户参数页码数 page 和 每页显示的数目 pageSize，其中 page 是必须传递的参数，pageSize 为可选参数，默认为 10

- 编写 SQL 语句，利用 limit 和 OFFSET 关键字进行分页查询

- 查询数据库，返回总数据量、总页数、当前页数据给前端

代码如下：

```js
router.all('./api', function (req, res, next) {
  var param = '';
  // 获取参数
  if (req.method == 'POST') {
    param = req.body;
  } else {
    param = req.query || req.params;
  }

  if (param.page == '' || param.page == null || page.page == undefined) {
    res.end(JSON.stringify({ msg: '请传入参数page', status: '102' }));
    return;
  }

  const pageSize = param.pageSize || 10;
  const start = (param.page - 1) * pageSize;
  const sql = `SELECT * FROM record limit ${pageSize} OFFSET ${start};`;

  pool.getConnection(function (err, connection) {
    if (err) throw err;
    connection.query(sql, function (err, result) {
      connection.release();
      if (err) {
        throw err;
      } else {
        // 计算总页数
        var allCount = result[0][0]['COUNT(*)'];
        var allPage = parseInt(allCount) / 20;
        var pageStr = allPage.toString();

        // 不能被整除
        if (pageStr.indexOf('.') > 0) {
          allPage = parseInt(pageStr.split('.')[0]) + 1;
        }
        var list = result[1];
        res.end(
          JSON.stringify({
            msg: '操作成功',
            status: '200',
            totalPages: allPage,
            currentPage: param.page,
            totalCount: allCount,
            data: list,
          })
        );
      }
    });
  });
});
```

总而言之，分页的关键在于：**首先确定每页显示的数量 pageSize，然后根据当前页的索引 pageIndex （从 1 开始），确定 LIMIT 和 OFFSET 应该设定的值**

- LIMIT 总是设定为 pageSize

- OFFSET 计算方式为 pageSize\*（pageIndex -1）

确定了这两个值，就能查询到第 N 页的数据。

### 如何实现 jwt 鉴权机制？

#### 概念

JWT（JSON WEB Token），本质上就是一个字符串书写规范，用于在用户与服务器之间传递安全可靠的信息。

目前很多公司的项目都是前后端分离的，使用 token 鉴权机制用于身份验证是最常见的方案，具体实现思路如下：

- 服务器当验证用户账号与密码正确时，给用户颁发一个令牌，这个令牌作为后续用户访问一些接口的凭证

- 后续访问会根据这个令牌判断用户是否有权进行访问

`Token` 分为三部分，头部（header）、载荷（Payload）、签名（Signature），并以 `.` 进行拼接。其中头部和载荷都是以 JSON 格式存放数据，只是进行了编码。

1. h

每个 JWT 都会有头部信息，主要用于声明使用的算法。声明算法的字段名为 alg，同时还有一个 try 的字段，默认 JWT 即可。以下示例中算法为 HS256

```js
{"alg": "HS256","type": "JWT"}
```

因为 JWT 是字符串，所以我们还需对以上内容进行 base64 编码，编码后字符串如下：

```js
eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9;
```

2. payload

载荷即消息体，会存放实际的内容，也就是 token 的数据声明，例如用户的 id 和 name，默认情况下也会携带令牌的签发时间 iat，通过还可以设置过期时间，如下：

```js
{
 "sub": "1234567890",
 "name": "John Doe",
 "iat": 1516239022
}
```

同样进行 base64 编码后，字符串如下：

```js
eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ;
```

3. Signature

签名是对头部和载荷内容进行签名，一般情况下，设置一个 secretKey，对前两个结果进行 HMACSHA25 算法，公式如下：

```js
Signature = HMACSHA256(base64Url(header)+.+base64Url(payload),secretKey)
```

一旦前面两部分数据被改了，只要服务器加密用的密钥没有泄露，得到的签名肯定与之前的签名不一样。

#### 实现方案

`Token`的使用分成了两部分：

- 生成 Token：登录成功的时候，颁发 Token

- 验证 Token：访问某些资源或者接口时，验证 Token

##### 生成 Token

借助第三方库 jsonwebtoken 通过 jsonwebtoken 的 sign 方法生成一个 token:

1. 第一个参数指的是 payload

2. 第二个是秘钥，服务端特有的

3. 第三个参数是 option，可以定义 token 过期时间

```js
const crypto = require('crypto'),
  jwt = require('jsonwebtoken');
// TODO: 使用数据库
// 这里应该是用数据库存储，这里只是演示用
let userList = [];

class UserController {
  // 用户登录
  static async login(ctx) {
    const data = ctx.request.body;
    if (!data.name || !data.password) {
      return (ctx.body = {
        code: '000002',
        message: ' 参数不合法',
      });
    }
    const result = userList.find(
      (item) =>
        item.name === data.name &&
        item.password ===
          crypto.createHash('md5').update(data.password).digest('hex')
    );
    if (result) {
      // 生成token
      const token = jwt.sign(
        {
          name: result.name,
        },
        'test_token', // secret
        { expiresIn: 60 * 60 } // 过期时间 ：60 * 60 s
      );
      return (ctx.body = {
        code: '0',
        message: ' 登录成功',
        data: {
          token,
        },
      });
    } else {
      return (ctx.body = {
        code: '000002',
        message: '用户名或密码错误 ',
      });
    }
  }
}
module.exports = UserController;
```

在前端接收到 token 后，一般情况下会通过 localStorage 进行缓存，然后将 token 放到 HTTP 请求头 Authorization 中，关于 Authorization 的设置，前面要加上 Bearer，注意后面带有空格

```js
axios.interceptors.request.use((config) => {
  const token = localStorage.getItem('token');
  config.headers.common['Authorization'] = 'Bearer ' + token; // 留意这里的Authorization
  return config;
});
```

##### 验证 Token

使用 `koa-jwt` 中间件进行验证，方式较简单

```js
// 注意：放在路由前面
app.use(
  koajwt({
    secret: 'test_token',
  }).unless({
    //配置白名单
    path: [/\/api\/register/, /\/api\/login/],
  })
);
```

- secret 必须和 sign 的时候保持一致

- 可以通过 unless 配置接口白名单，也就是那些 URL 可以不经过校验，像登录、注册都可以不用校验

- 校验的中间件需要放在需要校验的路由前面，无法对前面的 URL 进行校验

获取 token 用户的信息方法如下：

```js
router.get('/api/userInfo', async (ctx, next) => {
  const authorization = ctx.header.authorization; // 获取jwt
  const token = authorization.replace('Bearer ', '');
  const result = jwt.verify(token, 'test_token');
  ctx.body = result;
});
```

注意： 上面的 HMA256 加密算法为单秘钥的形式，一旦泄露后果不堪设想。

在分布式系统中，每个子系统都要获取到秘钥，那么这个子系统根据该秘钥可以发布和验证令牌，但有些服务器只需要验证令牌；

这时，可以采用非对称加密，利用私钥发布令牌，公钥验证令牌，加密算法可以选择 RS256。

#### 优缺点：

1. 优点：

- json 具有通用性，所以是可以跨语言的

- 组成简单，字节占用小，便于传输

- 服务端无需保存会话信息，很容易进行水平扩展

- 可防护 CSRF 攻击

2. 缺点：

- payload 部分仅仅是进行简单编码，所以只能用于存储逻辑必须的非敏感信息

- 需要保护好加密密钥，一旦泄露后果很严重

- 为避免 token 被劫持，最好使用 https 协议

### 怎么上传文件？

#### 概念

文件上传，我们需要设置请求头为： `content-type: multipart/form-data`

> multipart 互联网上的混合资源，就是资源由多种元素组成，form-data 表示可以使用 HTML Forms 和 POST 方法上传文件

结构如下：

```js
POST /t2/upload.do HTTP/1.1
User-Agent: SOHUWapRebot
Accept-Language: zh-cn,zh;q=0.5
Accept-Charset: GBK,utf-8;q=0.7,*;q=0.7
Connection: keep-alive
Content-Length: 60408
Content-Type:multipart/form-data; boundary=ZnGpDtePMx0KrHh_G0X99Yef9r8JZsR
JSXC
Host: w.sohu.com

--ZnGpDtePMx0KrHh_G0X99Yef9r8JZsRJSXC
Content-Disposition: form-data; name="city"

Santa colo
--ZnGpDtePMx0KrHh_G0X99Yef9r8JZsRJSXC
Content-Disposition: form-data;name="desc"
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

...
--ZnGpDtePMx0KrHh_G0X99Yef9r8JZsRJSXC
Content-Disposition: form-data;name="pic"; filename="photo.jpg"
Content-Type: application/octet-stream
Content-Transfer-Encoding: binary

... binary data of the jpg ...
--ZnGpDtePMx0KrHh_G0X99Yef9r8JZsRJSXC--
```

boundary 表示分隔符，如果要上传多个表单项，就要使用 boundary 分割，每个表单项由---XXX 开始，以---XXX 结尾

XXX 是即时生成的字符串，用以确保整个分隔符不会在文件或表单项的内容中出现

每个表单项必须包含一个 Content-Disposition 头，其他的头信息则为可选项，比如：Content-Type

Content-Disposition 包含着了 type 和一个名字为 name 的 parameter，type 是 form-data，name 参数的值则为表单控件（也即 field）的名字，如果是文件，那么还有一个 filename 参数，值为文件名

```js
Content-Disposition: form-data;name="pic"; filename="photo.jpg"
```

至于使用 `multipart/form-data`，是因为文件是以二进制的形式存在，其作用是专门用于传输大型二进制数据，效率高。

#### 实现方案

关于文件的上传，可以分为两个步骤：

- 文件的上传

- 文件的解析

##### 文件的上传

前端文件上传的表单结构如下：

```html
<form
  action="http://localhost:8080/api/upload"
  method="post"
  enctype="multipart/form-data"
>
  <input type="file" name="file" id="file" value="" multiple="multiple" />
  <input type="submit" value=" " />
</form>
```

`action`就是我们要提交的接口，`enctype="multipart/form-data"`就是指定上传文件的格式，`input`的`name`属性一定是`file`

##### 文件的解析

在服务器中，这里采用`koa2`中间件的形式解析上传的文件数据，分别有下面两种形式：

- koa-body

- koa-multer

###### koa-body

1. 安装依赖

```js
npm install koa-body ;
```

2. 引入 `koa-body`中间件

```js
const koaBody = require('koa-body');
app.use(
  koaBody({
    multipart: true,
    formidable: {
      maxFileSize: 200 * 1024 * 1024, // 设置上传文件 大小最大限制，默认为2M
    },
  })
);
```

3. 获取上传的文件

```js
const file = ctx.request.files.file; // 获取上传文件
```

获取文件数据后，可以通过 fs 模块将文件保存到指定目录

```js
router.post('/uploadFile', async (ctx, next) => {
  //上传单个文件
  const file = ctx.request.files.file; //
  // 创建可读流
  const reader = fs.createReadStream(file.path);
  let filePath = path.join(__dirname, 'public/upload/') + `/${file.name}`;
  // 创建可写流
  const upStream = fs.createWriteStream(filePath);
  // 可读流通过管道写入可写流
  reader.pipe(upStream);
  return (ctx.body = '上传成功！');
});
```

###### koa-multer

1. 安装依赖

```js
npm install koa-multer ;
```

2. 使用`multer`中间件实现文件上传

```js
const storage = multer.diskStorage({
  destination: (req, file, cb) => {
    cb(null, './upload/');
  },
  filename: (req, file, cb) => {
    cb(null, Date.now() + path.extname(file.originalname));
  },
});

const upload = multer({
  storage,
});

const fileRouter = new Router();
fileRouter.post('/upload', upload.single('file'), (ctx, next) => {
  console.log(ctx.req.file); // 获取文件
});

app.use(fileRouter.routes());
```

### Node 性能如何进行监控以及优化？

#### 性能衡量指标

- CPU

主要分为两部分：

1. CPU 负载：在某个时间段内，占用以及等待 CPU 的进程总数

2. CPU 使用率：CPU 时间占用状况，等于 1 - 空闲 CPU 时间/ CPU 总时间

这两个指标都是用来评估系统当前 CPU 的繁忙程度的量化指标

Node 应用一般不会消耗很多的 CPU，如果 CPU 占用率高，则表明应用存在很多同步操作，导致异步任务回调被阻塞

- 内存

内存时一个非常容易量化的指标。内存占用率是评判一个系统的内存瓶颈的常见指标。对于 Node 来说，内部内存堆栈的使用状态也是一个可以量化的指标

```js
// /app/lib/memory.js
const os = require('os');

// 获取当前Node内存堆栈情况
const  { rss, heapUsed, heapTotal} = process.memoryUsage();

// 获取紫铜空闲内存
const sysFree = os.freemen();

// 获取系统总内存
const SYSTotal = os.totalmen();

module.exports = {
  memory: () => {
    return: () => {
      sys: 1 - sysFree/sysTotal;// 系统内存占用率
      heap: heapUsed / heapTotal;// Node堆内存占用率
      node: rss/sysTotal;// Node占用系统内存的比例
    }
  }
}
```

> rss: 表示 node 进程占用的内存总量
> heapTotal: 表示堆内存的总量
> heapUsed: 实际堆内存的使用量
> external: 外部程序的内存使用量，包含 Node 核心的 C++程序的内存使用量

Node 中，一个进程的最大内存容量为 1.5G，因此我们需要减少内存泄露。

- I/O

硬盘的 I/O 开销是非常昂贵的，硬盘 I/O 花费的 CPU 时钟周期是内存的 164000 倍

内存 IO 比磁盘 IO 快很多，所以使用内存缓存数据是有效的优化方法。常用的工具如 Redis、memcached 等

并不是所有的数据都需要缓存，访问率高的，生成代码比较高的才考虑缓存，也就是说影响你性能瓶颈的考虑去缓存，并且缓存还可能伴随着缓存雪崩、缓存穿透等问题

- 网络

网络这个就不需要多解释了，我们都熟悉的日常使用的网络

#### 如何监控？

关于性能方面的监控，我们一般借助工具来实现。

我摸着这里采用`Easy-Monitor 2.0`，其是轻量级的 Node.js 项目内核性能监控 + 分析工具，在默认模式下，只需要在项目入口文件 require 一次，无需改动任何业务代码即可开启内核级别的性能监控分析。

使用方法：

在你的项目入口中按照如下方式引入，当然请先传入你的项目名称：

```js
const easyMonitor = require('easy-monitor');
easyMonitor('你的项目名称');
```

打开你的浏览器，访问`http://loacalhost:12333`，即可看到进程页面

#### 如何优化？

关于优化，可以从下面几个方面考虑：

- 使用最新版的 Node.js

- 正确使用流 Stream

- 代码层面优化

- 内存管理的优化

##### 使用最新版的 Node.js

每个版本的性能提升主要来自于两个方面：

1. V8 的版本更新

2. Node.js 内部代码的更新优化

##### 正确使用流 Stream

在 Node 中，很多对象都实现了流，对于一个大文件可以通过流的形式发送，不需要将其完全读入内存

```js
const http = require('http');
const fs = require('fs');

// bad
http.createServer(function (req, res) {
  fs.readFile(__dirname + '/data.txt', function (err, data) {
    res.end(data);
  });
});

// good
http.createServer(function (req, res) {
  const stream = fs.createReadStream(__dirname + '/data.txt');
  stream.pipe(res);
});
```

##### 代码层面优化

合并查询，将多次查询合并一次，减少数据库的查询成绩次数

```js

// bad
for user_id in userIds
 let account = user_account.findOne(user_id)

// good
const user_account_map = {} // 注意这个对象将会消耗⼤量内存。
user_account.find(user_id in user_ids).forEach(account){
 user_account_map[account.user_id] = account
}
for user_id in userIds
 var account = user_account_map[user_id]
```

##### 内存管理的优化

在 V8 中，主要讲内存分为新生代和老生代：

- 新生代：对象存活时间较短。新生对象或值经过一次垃圾回收的对象

- 老生代：对象存活时间较长。经历一次或者多次垃圾回收的对象

若新生代内存空间不够，直接分配到老生代。

通过减少内存占用，可以提高服务器的性能。如果有内存泄露，也会导致大量的对象存储到老生代中，服务器性能会大大降低。

```js
const buffer = fs.readFileSync(__dirname + '/source/index.html');

app.use(
  mount('/', async(ctx) => {
    ctx.status = 200;
    ctx.type = 'html';
    ctx.body = buffer;
    leak.push(fs.readFileSync(__dirname + '/source/index.html);
  })
);

const leak = {};
```

leak 的内存非常大，造成内存泄露，应当避免这样的操作，通过减少内存使用，是提高服务性能的手段之一

而节省内存最好的方式是使用池，其将频繁使用、可复用对象存储起来，减少创建和销毁操作

例如有个图片请求接口，每次请求，都需要用到类。若每次都需要重新 new 这些类，并不是很合适，在大量请求时，频繁创建和销毁这些类，造成内存抖动。

使用对象池的机制，对这种频繁需要创建和销毁的对象保存在一个对象池中。每次用到该对象时，就取对象池空闲的对象，并对其进行初始化操作，从而提高框架的性能。
